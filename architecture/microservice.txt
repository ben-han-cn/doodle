api design:
    in seperate doc which is seprated from code
    "user": {
        "description": "Represent a single user in the system",
        "fields": [
            {"name": "id", "type": "string"},
            {"name": "email", "type": "string", "required": false, "annotations": ["personal_data"]},
            {"name": "name", "type": "name", "annotations": ["personal_data"]},
            {"name": "status", "type": "user_status", "default": "active"},
        ]
    }

    //which is used to create user
    "user_from": {
    "fields": [
            {"name": "email", "type": "string", "required": false, "annotations": ["personal_data"]},
            {"name": "password", "type": "string", "required": false, "annotations": ["personal_data"]},
            {"name": "name", "type": "name_form", "required": false, "annotations": ["personal_data"]},
        ]
    }

    it should be consistent in the scope of entire company (validate use linter)
    automatic test to make sure the document is confirmed with the service
    code generation tool to generate service/http routing function for the framework


database architecture
    echo micro service application own its database
    no other service is allowed to connect to the database
    other service use only the service interface (API + Events) 

    tool to generate the db, table from the resource definition
    (add hash_code to object to check whether it has changed to avoid unnecessary io operation)


continuous delivery is very important
    deploy trigger by a git change(commit or tag) --- delta

standard health check
    "models": {
        "healthcheck": {
            "fields": [
                {"name" : "status", "type": "string", "example": "heathy"}
            ]
        }
    }

    "resources": {
        "healthcheck": {
            "path": "/_internal_",
            "operations": [
            {
                "method": "GET",
                "path": "/healthcheck",
                "response": {
                    "200": {"type": "healthcheck"},
                    "422": {"type": "io.flow.error.v0.models.generic_error"}
                }
            ]
        }
    }


we have an amazing api, but please subscribe to our evnet streams instead
event interface:
    first class schema for all events
    "unions": {
        "user_event": {
            "discriminator": "discriminator",
            "types": [
                {"type": "user_upserted"},
                {"type": "user_deleted"}
            ]
        }
    }

    "models": {
        "user_upserted": {
            "fields": [
                {"name": "event_id", "type": "string"},
                {"name": "timestamp", "type": "date-time-iso8601"},
                {"name": "user", "type": "io.flow.common.v0.models.user"}
            ]
        },

        "user_deleted":  {
            "fields": [
                {"name": "event_id", "type": "string"},
                {"name": "timestamp", "type": "date-time-iso8601"},
                {"name": "user", "type": "io.flow.common.v0.models.user"}
            ]
        }
    }
    producer guarantee at least once delivery
    consumers implememt idempotency

producer:
    create a journal of All operations on table (journal like event source)
    record operation (insert, update, delete)
    on creation, queue the journal record to be published
    real time, async, publish 1 event per journal record
    enable replay by simply queueing journal record

consumer:
    store new events in local database, partitioned for fast removal
    on event arrival, queue record to be consumed
    process incoming event in micro batch(by default every 250ms)
    record failure locally(report to center monitor system)

stream:
    has lib to handle stream
    stream has name which also should include the serialization method (json, grpc, etc)
    stream lib should easy for local end to end test (in memory queue)


dependencies:
    upgrade all servies every week to latest dependecies
    dependencies tracking



go-lang:
    https://github.com/goadesign/goa.git
    https://github.com/go-kit/kit


core axioms
    no components are privileged
    all components communicate in the same simple, homogeneous way
    components can be composed from other components

service communication
    rpc                    -->    command
    message queue          -->    event
service dependency (service <-> class)
    dependency tree
    depth of tree affect latency, set performance target
    merge service

data consistent

service mesh
    network of service proxy
    proxy ---> routing
               load balanceing
               health check
               retry + meltdown mechanism
               security

microservice arch expose much more bigger/widder attack interface 

Different performance, data-safety, security and scaling requirement for diffrerent microservice

microservice allow you to separate business-logic code from infrastructure code.
infrastructure code --> scaling, self healing, monitoring ...



functional breakdown
services and inter communication/message flow

message:
    synchronous  -- command
    asynchronous -- event
    oberve       -- others can see it
    consume      -- others cann't see it

asynchronous message:
    make interface idempotent
    message queue should support deliver at-least-once behavior
    message should contain metadata to identify

data
    data is heterogeneous not homogeneous -- relational db, document db, key-value db
    CQRS(command query responsibility segregation) 
        synchronous read and asynchronous write
        performance and eventual consistency.
    UUID is a default choice for primary key 
    data will be duplicated in different serivce and in this case, eventually consistency is preferred.



CD -- the ability to safely deploy a component(service) to production at any time
essential pipeline:
    version-controlled local development environment for each service, supported by unit test
    staging env to both validate the micorservice and build, reproducibly, and arifact for deployment
