Affinity
comes in two falvors:
    node affinity
    pod affinity


node affinity will replace node selector in pod
apiVersion: v1
kind: Pod
metadata:
 name: kubia-gpu
spec:
 affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: gpu
          operator: In
          values:
            - "true"
node affinity provide two more advanced feature:
1 more flexible matching algorithm 
2 will affect running pods if node label changed (in the future k8s version)
3 Prioritizing nodes when scheduling a pod

preferredDuringSchedulingIgnoredDuringExecution:
 - weight: 80
   preference:
      matchExpressions:
      - key: availability-zone
        operator: In
        values:
        - zone1
 - weight: 20
   preference:
      matchExpressions:
      - key: share-type
        operator: In
        values:
        - dedicated 


pod affinity to make pod close to each other
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
 name: frontend
spec:
 replicas: 5
 template:
 ...
 spec:
 affinity:
  podAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - topologyKey: kubernetes.io/hostname
      labelSelector:
        matchLabels:
          app: backend 


for affinity, 
  requiredDuringSchedulingIgnoredDuringExecution //hard requirement
  preferredDuringSchedulingIgnoredDuringExecution //optional 


anti-affinity: avoid pod resides in same node, possibly they will affect each other's performance
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - topologyKey: kubernetes.io/hostname
      labelSelector:
        matchLabels:
          app: frontend 

how affinity and anti-affinity work:
1 labelSelector is used to find target pods
2 get the nodes which target pods resides
3 according to topologyKey to schedule
    kubernetes.io/hostname                      //same host
    failure-domain.beta.kubernetes.io/zone      //same zone
    failure-domain.beta.kubernetes.io/region    //same region
    rack                                        //same rack
    (the first three label is defined by kubernetes, the last one is customized,
     for affinity, it means scheduler will prefer nodes with the same value of the label 
     key in target nodes, for anti-affinity scheduler perfer nodes with different label 
     value of the label key specified in topologyKey)
